# TODO: caches prompts and responses for increased performance fot frequently ran prompts.
# this needs to be more advanced than any prompt caching tech made by LLM providers
# squieze every ounce of efficiency out of it