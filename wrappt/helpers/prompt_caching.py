# TODO: caches prompts and responses for increased performance for frequently ran prompts.
# this needs to be more advanced than any prompt caching tech made by LLM providers
# squeeze every ounce of efficiency out of it